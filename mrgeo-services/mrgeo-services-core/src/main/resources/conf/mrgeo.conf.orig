# These paths will probably stay the same
image.base = /mrgeo/images
vector.base = /mrgeo/vectors
kml.base = /mrgeo/kml
tsv.base = /mrgeo/tsv
colorscale.base = /mrgeo/color-scales

# This is the spot in HDFS where jars are distributed for the mappers/reducers
distributed.base = /mrgeo/jars

# Path(s) to gdal shared libraries, separated by ":".
# Currently, we use: libgdal, libgdaljni.so, libgdalconstjni, and libosrjni.so
gdal.path = /usr/lib:/usr/lib/jni

# Denote which cluster type you have.  Mainly used for Spark processing.  Valid values
# are: yarn, spark, and local
cluster=yarn

# The prefered provider to use if there are more than one, and the provider is missing
# from the name.  Can use preferred.provider for all the types, or each one uniquely
preferred.provider = hdfs
#preferred.image.provider = hdfs
#preferred.vector.provider = hdfs
#preferred.adhoc.provider = hdfs

# Use Kryo serialization for Spark jobs, if using Spark < 1.3.0, this _MUST_ be false!
use.kryo.serialization=false

# Memory intensive (Spark) job memory multiplier.  This parameter specifies a multiplier for the
# amount of memory to give to memory intensive jobs.  For example, if YARN was configured to give
# 2G (2048m) to a job, a multiplier of 2 would yield 4G, 1.5 would yield 3G.  The total number of
# concurrent tasks will be be lowered by the appripriate amount
memoryintensive.multiplier = 2

# This is the maximum amount of memory to give to the workers for mrgeo processing.  Any memory
# above this will be allocated to Spark shuffle and cache, based on the shuffle.fraction property.
# The calculations WILL NOT kick in until there is twice the memory as max.processing.memory.  If
# the worker memory is less than twice max.processing.memory, 1/2 will go to processing, and the
# rest will be distributed to shuffle and storage based on the shuffle fraction.
# For example, if max.processing.memory is 1G, when the worker reaches 2G or more, 1G will be allocated
# to mrgeo for processing and the rest allocated to shuffle & storage.
max.processing.memory=1024m
shuffle.fraction=0.5

# Additional classpath elements used for finding dependencies used in distributed
# processing.  These are added AFTER MRGEO_HOME dependencies, but before
# any others on the classpath
#dependency.classpath=

# Additional hadoop parameters as well as parameters needed for Giraph.
# Either hadoop.params with -libjars and the path to <giraph-with-dependencies>,
# or zooservers pointing to existing zookeeper host/port(s) need to be set
#zooservers=host1:port1,host2:port2,host3:port3
#hadoop.params=-libjars /usr/local/mrgeo/giraph/giraph-core/1.0.0/giraph-core-1.0.0.jar

# Modify this to match your server config. You may need to change the port, etc.  Do not remove
# the trailing forward slash.
# NOTE:  This appears only to be used in the KMLGenerator and tests.  Look to remove it...
base.url = http://localhost:8080/mrgeo/

# Size of a mrsimage tile (this should not be changed unless there is a great reason)
mrsimage.tilesize = 512
